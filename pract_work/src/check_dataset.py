import os
from PIL import Image
import numpy as np
from collections import Counter

def get_basename_without_ext(filename):
    return os.path.splitext(filename)[0]

def analyze_dataset(img_dir, ann_dir, img_suffix='.jpg', ann_suffix='.png'):

    img_files = {get_basename_without_ext(f): f for f in os.listdir(img_dir) if f.endswith(img_suffix)}
    ann_files = {get_basename_without_ext(f): f for f in os.listdir(ann_dir) if f.endswith(ann_suffix)}

    img_basenames = set(img_files.keys())
    ann_basenames = set(ann_files.keys())

    common = img_basenames & ann_basenames
    only_img = img_basenames - ann_basenames
    only_ann = ann_basenames - img_basenames

    print("ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ¸Ğ¼Ñ‘Ğ½ (Ğ¿Ğ¾ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ¸Ğ¼ĞµĞ½Ğ¸)...")
    if only_img:
        print(f"Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ±ĞµĞ· Ğ°Ğ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¹ ({len(only_img)} ÑˆÑ‚.):")
        for name in sorted(list(only_img))[:5]:
            print(f"    {name}{img_suffix}")
    if only_ann:
        print(f"ĞĞ½Ğ½Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ({len(only_ann)} ÑˆÑ‚.):")
        for name in sorted(list(only_ann))[:5]:
            print(f"    {name}{ann_suffix}")

    if not only_img and not only_ann:
        print("Ğ’ÑĞµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¸Ğ¼ĞµÑÑ‚ Ğ¿Ğ°Ñ€Ñƒ.")
    else:
        print(f"â„¹Ğ‘ÑƒĞ´ĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ {len(common)} Ğ¿Ğ°Ñ€.")


    all_pixels = []
    size_mismatch = []

    for base in sorted(common):
        img_path = os.path.join(img_dir, img_files[base])
        ann_path = os.path.join(ann_dir, ann_files[base])

        img = Image.open(img_path)
        ann = Image.open(ann_path)

        if img.size != ann.size:
            size_mismatch.append(base)

        ann_arr = np.array(ann)
        all_pixels.extend(ann_arr.flatten())

    if size_mismatch:
        print(f"\nĞĞµÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ² Ñƒ {len(size_mismatch)} Ğ¿Ğ°Ñ€ (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹):")
        for name in size_mismatch[:5]:
            print(f"    {name}")
    else:
        print("\nĞ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ°ÑĞ¾Ğº ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚.")

    pixel_counter = Counter(all_pixels)
    classes = sorted(pixel_counter.keys())
    total = sum(pixel_counter.values())

    print(f"\nĞ£Ğ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ°ÑĞ¾Ğº (ĞºĞ»Ğ°ÑÑÑ‹): {classes}")
    print("Ğ Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹ Ğ¿Ğ¾ ĞºĞ»Ğ°ÑÑĞ°Ğ¼:")
    for cls in classes:
        count = pixel_counter[cls]
        pct = count / total * 100 if total > 0 else 0
        print(f"  ĞºĞ»Ğ°ÑÑ {cls}: {count:>10} Ğ¿Ğ¸ĞºÑĞµĞ»ĞµĞ¹ ({pct:>6.3f}%)")

    return list(common)


IMG_DIR = "../dataset/train_dataset_for_students/img/train"
ANN_DIR = "../dataset/train_dataset_for_students/labels/new_train"

if __name__ == "__main__":
    print("ğŸ” ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°...\n")
    common_files = analyze_dataset(IMG_DIR, ANN_DIR, img_suffix='.jpg', ann_suffix='.png')